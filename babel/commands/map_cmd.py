"""
MapCommand — Git-native project structure mapping for LLM understanding

Generates .babel/map.md with:
- Curated directory structure (from git ls-tree)
- Key files detected by commit frequency (data-driven)
- Module docstrings and signatures
- Entry points and architecture overview

WHY: LLMs waste tokens rediscovering project structure every session.
A curated map provides instant understanding.

Architecture:
- Git handles file filtering (.gitignore respected automatically)
- Commit frequency detects important files (no hardcoded patterns)
- AST extracts Python docstrings and signatures
- Output is curated, not a dump
"""

import ast
import json
import subprocess
from collections import Counter
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Optional, Tuple

from ..commands.base import BaseCommand
from ..presentation.symbols import safe_print
from ..core.symbols import CodeSymbolStore


class MapCommand(BaseCommand):
    """
    Git-native project structure mapping.

    P7 (Reasoning Travels): The map helps LLMs understand project structure
    without expensive exploration, preserving tokens for actual work.
    """

    MAP_HEADER = '''<!--
PROJECT MAP — Auto-generated by Babel (Git-native)
Purpose: Help LLMs understand project structure quickly

IMPORTANT: Update this file when structure changes
Regenerate: babel map --refresh
Last updated: {timestamp}
-->

'''

    def _get_map_path(self) -> Path:
        """Get path to map.md file."""
        return self.babel_dir / "map.md"

    def _get_cache_path(self) -> Path:
        """Get path to map cache file."""
        return self.babel_dir / "map_cache.json"

    # -------------------------------------------------------------------------
    # Git-Native File Operations
    # -------------------------------------------------------------------------

    def _git_command(self, args: List[str], timeout: int = 30) -> Optional[str]:
        """Run a git command and return stdout, or None on failure."""
        try:
            result = subprocess.run(
                ['git'] + args,
                cwd=self.project_dir,
                capture_output=True,
                text=True,
                timeout=timeout
            )
            if result.returncode == 0:
                return result.stdout.strip()
        except Exception:
            pass
        return None

    def _get_tracked_files(self) -> List[Path]:
        """
        Get all tracked files using git ls-files.

        .gitignore is automatically respected.
        """
        output = self._git_command(['ls-files'])
        if not output:
            return []

        return [Path(f) for f in output.split('\n') if f]

    def _get_directory_structure(self) -> Dict[str, List[str]]:
        """
        Get clean directory structure from git.

        Returns dict of {directory: [files]} for top-level dirs only.
        """
        files = self._get_tracked_files()

        structure = {}
        for f in files:
            parts = f.parts
            if len(parts) == 1:
                # Root level file
                if '.' not in structure:
                    structure['.'] = []
                structure['.'].append(str(f))
            else:
                # File in directory
                top_dir = parts[0]
                if top_dir not in structure:
                    structure[top_dir] = []
                structure[top_dir].append(str(f))

        return structure

    def _get_hot_files(self, limit: int = 15, since: str = "6 months ago") -> List[Tuple[Path, int]]:
        """
        Detect important files by git commit frequency.

        Files with more commits = more important (data-driven detection).
        """
        # Get commit history for Python files
        output = self._git_command([
            'log', '--name-only', '--format=',
            f'--since={since}', '--', '*.py'
        ])

        if not output:
            # Fallback: try without date filter
            output = self._git_command([
                'log', '--name-only', '--format=',
                '-n', '500', '--', '*.py'
            ])

        if not output:
            return []

        # Count file occurrences
        files = [f for f in output.split('\n') if f and f.endswith('.py')]
        counts = Counter(files)

        # Return top files with counts
        return [(Path(f), count) for f, count in counts.most_common(limit)]

    def _get_recent_changes(self, limit: int = 10) -> List[Tuple[Path, str]]:
        """
        Get recently changed files with their last commit message.

        Shows active development areas.
        """
        output = self._git_command([
            'log', '--name-only', '--format=%s',
            '-n', str(limit * 2), '--', '*.py'
        ])

        if not output:
            return []

        results = []
        lines = output.split('\n')
        current_message = ""

        for line in lines:
            if not line:
                continue
            if not line.endswith('.py'):
                current_message = line[:50]
            else:
                if len(results) < limit:
                    results.append((Path(line), current_message))

        return results

    def _detect_project_type(self) -> str:
        """
        Detect project type from files.

        Returns: 'python_package', 'python_cli', 'python_web', 'python_generic'
        """
        files = self._get_tracked_files()
        file_names = {f.name.lower() for f in files}

        has_pyproject = 'pyproject.toml' in file_names
        has_setup = 'setup.py' in file_names
        has_cli = 'cli.py' in file_names or '__main__.py' in file_names
        has_app = 'app.py' in file_names or 'wsgi.py' in file_names
        has_manage = 'manage.py' in file_names

        if has_manage:
            return "python_django"
        elif has_app:
            return "python_web"
        elif has_cli:
            return "python_cli"
        elif has_pyproject or has_setup:
            return "python_package"
        else:
            return "python_generic"

    def _get_entry_points(self) -> List[Path]:
        """
        Detect entry points based on project type and file patterns.
        """
        files = self._get_tracked_files()
        entry_patterns = {'main.py', 'cli.py', 'app.py', '__main__.py', 'manage.py', 'server.py', 'wsgi.py'}

        entries = []
        for f in files:
            if f.name.lower() in entry_patterns:
                entries.append(f)

        # Also check pyproject.toml for declared entry points
        return entries

    # -------------------------------------------------------------------------
    # Python AST Analysis (kept from original)
    # -------------------------------------------------------------------------

    def _extract_python_docstring(self, file_path: Path) -> Optional[str]:
        """Extract module docstring from a Python file."""
        try:
            full_path = self.project_dir / file_path
            content = full_path.read_text(encoding='utf-8', errors='ignore')

            # Limit file size to avoid memory issues
            if len(content) > 100000:  # 100KB limit
                return None

            tree = ast.parse(content)
            docstring = ast.get_docstring(tree)

            if docstring:
                lines = docstring.split('\n')
                if len(lines) > 3:
                    return '\n'.join(lines[:3]) + '...'
                return docstring
        except Exception:
            pass
        return None

    def _extract_python_signatures(self, file_path: Path, max_items: int = 5) -> List[str]:
        """Extract class and function signatures from a Python file."""
        signatures = []
        try:
            full_path = self.project_dir / file_path
            content = full_path.read_text(encoding='utf-8', errors='ignore')

            if len(content) > 100000:
                return []

            tree = ast.parse(content)

            # Only get top-level definitions
            for node in ast.iter_child_nodes(tree):
                if len(signatures) >= max_items:
                    break

                if isinstance(node, ast.ClassDef):
                    signatures.append(f"class {node.name}")
                elif isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                    if not node.name.startswith('_'):
                        prefix = "async " if isinstance(node, ast.AsyncFunctionDef) else ""
                        signatures.append(f"{prefix}def {node.name}()")
        except Exception:
            pass

        return signatures

    def _get_readme_summary(self) -> Optional[str]:
        """Extract summary from README file."""
        for name in ['README.md', 'README.rst', 'README.txt', 'README']:
            readme_path = self.project_dir / name
            if readme_path.exists():
                try:
                    content = readme_path.read_text(encoding='utf-8', errors='ignore')
                    lines = content.split('\n')

                    # Skip title, get first content paragraph
                    in_content = False
                    summary_lines = []

                    for line in lines:
                        if not in_content:
                            if line.startswith('#') or line.startswith('='):
                                in_content = True
                            continue
                        if not line.strip():
                            if summary_lines:
                                break
                            continue
                        summary_lines.append(line)
                        if len(summary_lines) >= 3:
                            break

                    if summary_lines:
                        return ' '.join(summary_lines)
                except Exception:
                    pass
        return None

    # -------------------------------------------------------------------------
    # Map Generation (Curated Output)
    # -------------------------------------------------------------------------

    def _generate_map_content(self) -> str:
        """Generate curated map.md content."""
        lines = []

        # Header
        lines.append(self.MAP_HEADER.format(
            timestamp=datetime.now().strftime('%Y-%m-%d %H:%M')
        ))

        # Title and project type
        project_type = self._detect_project_type()
        lines.append("# Project Map\n")
        lines.append(f"**Type:** {project_type.replace('_', ' ').title()}\n")

        # Overview from README or Babel purpose
        readme_summary = self._get_readme_summary()
        purpose_node = self._cli._get_active_purpose()

        if readme_summary:
            lines.append("## Overview\n")
            lines.append(f"{readme_summary}\n")
        elif purpose_node:
            purpose_text = purpose_node.content.get('purpose',
                          purpose_node.content.get('summary', ''))
            if purpose_text:
                lines.append("## Overview\n")
                lines.append(f"{purpose_text}\n")

        # Directory structure (curated)
        lines.append("## Structure\n")
        structure = self._get_directory_structure()

        for dir_name in sorted(structure.keys()):
            file_count = len(structure[dir_name])
            if dir_name == '.':
                lines.append(f"- `/` ({file_count} files) — Root")
            else:
                # Try to get purpose from __init__.py docstring
                init_path = Path(dir_name) / '__init__.py'
                purpose = ""
                if (self.project_dir / init_path).exists():
                    docstring = self._extract_python_docstring(init_path)
                    if docstring:
                        purpose = f" — {docstring.split(chr(10))[0][:50]}"
                lines.append(f"- `{dir_name}/` ({file_count} files){purpose}")
        lines.append("")

        # Entry points
        entry_points = self._get_entry_points()
        if entry_points:
            lines.append("## Entry Points\n")
            for ep in entry_points:
                docstring = self._extract_python_docstring(ep)
                desc = f" — {docstring.split(chr(10))[0][:40]}" if docstring else ""
                lines.append(f"- `{ep}`{desc}")
            lines.append("")

        # Hot files (commit frequency)
        hot_files = self._get_hot_files(limit=10)
        if hot_files:
            lines.append("## Core Files (by commit frequency)\n")
            for f, count in hot_files:
                docstring = self._extract_python_docstring(f)
                signatures = self._extract_python_signatures(f, max_items=3)

                desc = ""
                if docstring:
                    desc = docstring.split('\n')[0][:40]

                lines.append(f"### `{f}` ({count} commits)\n")
                if desc:
                    lines.append(f"> {desc}\n")
                if signatures:
                    for sig in signatures:
                        lines.append(f"- `{sig}`")
                    lines.append("")

        # Footer
        lines.append("---")
        lines.append("*Generated by `babel map` (Git-native)*")
        lines.append("*Key files detected by commit frequency, not hardcoded patterns*")

        return '\n'.join(lines)

    # -------------------------------------------------------------------------
    # Cache Management
    # -------------------------------------------------------------------------

    def _load_cache(self) -> Dict:
        """Load cache from disk."""
        cache_path = self._get_cache_path()
        if cache_path.exists():
            try:
                return json.loads(cache_path.read_text(encoding='utf-8'))
            except Exception:
                pass
        return {"files": {}, "last_update": None, "commit_hash": None}

    def _save_cache(self, cache: Dict):
        """Save cache to disk."""
        cache_path = self._get_cache_path()
        cache["last_update"] = datetime.now().isoformat()

        # Store current HEAD commit
        head = self._git_command(['rev-parse', 'HEAD'])
        if head:
            cache["commit_hash"] = head

        cache_path.write_text(json.dumps(cache, indent=2), encoding='utf-8')

    def _has_changes_since_cache(self) -> Tuple[bool, str]:
        """
        Check if there are changes since last cache using git.

        Returns: (has_changes, reason)
        """
        cache = self._load_cache()
        cached_commit = cache.get("commit_hash")

        if not cached_commit:
            return True, "No cache found"

        current_commit = self._git_command(['rev-parse', 'HEAD'])
        if not current_commit:
            return True, "Cannot get current commit"

        if cached_commit != current_commit:
            # Count commits since cache
            count = self._git_command(['rev-list', '--count', f'{cached_commit}..HEAD'])
            return True, f"{count or 'Some'} commit(s) since last update"

        # Check for uncommitted changes
        status = self._git_command(['status', '--porcelain'])
        if status:
            changed_count = len([l for l in status.split('\n') if l])
            return True, f"{changed_count} uncommitted change(s)"

        return False, "Up to date"

    # -------------------------------------------------------------------------
    # Main Commands
    # -------------------------------------------------------------------------

    def show(self):
        """Show current map content (stdout)."""
        map_path = self._get_map_path()

        if not map_path.exists():
            print("No map found. Generating...")
            self.refresh()
            return

        content = map_path.read_text(encoding='utf-8')
        safe_print(content)

        # Succession hint (centralized)
        from ..output import end_command
        end_command("map", {})

    def refresh(self):
        """Regenerate map from scratch."""
        symbols = self.symbols
        map_path = self._get_map_path()

        print("Generating project map (Git-native)...")
        print("  Scanning tracked files...")
        print("  Analyzing commit frequency...")
        print("  Extracting docstrings...")

        content = self._generate_map_content()

        # Ensure babel dir exists
        self.babel_dir.mkdir(parents=True, exist_ok=True)

        # Write map
        map_path.write_text(content, encoding='utf-8')

        # Update cache
        self._save_cache(self._load_cache())

        # Stats
        lines = content.count('\n')
        files = self._get_tracked_files()
        hot_files = self._get_hot_files()

        print(f"\n{symbols.check_pass} Map generated: {map_path}")
        print(f"  Lines: {lines}")
        print(f"  Tracked files: {len(files)}")
        print(f"  Core files detected: {len(hot_files)}")
        print(f"\nView with: babel map")

        # Succession hint (centralized)
        from ..output import end_command
        end_command("map", {})

    def update(self):
        """Incremental update (regenerates only if git has changes)."""
        symbols = self.symbols
        map_path = self._get_map_path()

        if not map_path.exists():
            print("No existing map. Running full refresh...")
            self.refresh()
            return

        has_changes, reason = self._has_changes_since_cache()

        if not has_changes:
            print(f"{symbols.check_pass} Map is up to date.")
            cache = self._load_cache()
            print(f"  Last update: {cache.get('last_update', 'unknown')}")
            return

        print(f"Changes detected: {reason}")
        print("Regenerating map...")

        content = self._generate_map_content()
        map_path.write_text(content, encoding='utf-8')
        self._save_cache(self._load_cache())

        lines = content.count('\n')
        print(f"\n{symbols.check_pass} Map updated: {map_path}")
        print(f"  Lines: {lines}")

        # Succession hint (centralized)
        from ..output import end_command
        end_command("map", {})

    def status(self):
        """Show map status."""
        symbols = self.symbols
        map_path = self._get_map_path()

        print("\nProject Map Status")
        print("=" * 40)

        # Git status
        head = self._git_command(['rev-parse', '--short', 'HEAD'])
        branch = self._git_command(['branch', '--show-current'])
        print(f"Git:     {branch or 'detached'} @ {head or 'unknown'}")

        # Map status
        if map_path.exists():
            content = map_path.read_text(encoding='utf-8')
            lines = content.count('\n')
            mtime = datetime.fromtimestamp(map_path.stat().st_mtime)

            print(f"Status:  {symbols.check_pass} Exists")
            print(f"Path:    {map_path}")
            print(f"Size:    {lines} lines")
            print(f"Updated: {mtime.strftime('%Y-%m-%d %H:%M')}")

            # Check if up to date
            has_changes, reason = self._has_changes_since_cache()
            if has_changes:
                print(f"Version: {symbols.check_warn} {reason}")
            else:
                print(f"Version: {symbols.check_pass} Up to date")
        else:
            print(f"Status:  {symbols.check_fail} Not found")
            print(f"\nGenerate with: babel map --refresh")

        # File stats
        files = self._get_tracked_files()
        py_files = [f for f in files if f.suffix == '.py']
        print(f"\nProject: {len(files)} tracked files ({len(py_files)} Python)")

        # Succession hint (centralized)
        from ..output import end_command
        end_command("map", {})

    def init_if_missing(self) -> bool:
        """Create map if it doesn't exist."""
        map_path = self._get_map_path()

        if not map_path.exists():
            self.refresh()
            return True

        return False

    # -------------------------------------------------------------------------
    # Symbol Index Commands (CodeSymbolStore integration)
    # -------------------------------------------------------------------------

    def _get_symbol_store(self) -> CodeSymbolStore:
        """Get or create CodeSymbolStore instance."""
        if not hasattr(self, '_symbol_store'):
            self._symbol_store = CodeSymbolStore(
                babel_dir=self.babel_dir,
                events=self.events,
                graph=self.graph,
                project_dir=self.project_dir
            )
        return self._symbol_store

    def index(self, incremental: bool = False, path: str = None):
        """
        Build or update the code symbol index.

        Args:
            incremental: Only index changed files (git diff based)
            path: Specific path to index (required for full index, not needed for incremental)
        """
        symbols = self.symbols
        store = self._get_symbol_store()

        if incremental:
            print("Indexing changed files (incremental)...")
            files, syms = store.index_changed_files()

            if files == 0:
                print(f"{symbols.check_pass} Index is up to date (no changes detected).")
            else:
                print(f"\n{symbols.check_pass} Indexed {files} file(s), {syms} symbol(s).")
        else:
            # Whitelist principle: require explicit path to avoid indexing third-party code
            if not path:
                print("Error: path is required for indexing.")
                print("Use: babel map --index <path>")
                return

            print(f"Indexing path: {path}")

            # Build patterns for both Python and Markdown files
            if path.endswith('.py') or path.endswith('.md'):
                # Single file specified
                patterns = [path]
            else:
                # Directory - include both Python and Markdown
                patterns = [
                    f"{path}/**/*.py",
                    f"{path}/**/*.md"
                ]

            files, syms = store.index_project(patterns=patterns)

            print(f"\n{symbols.check_pass} Indexed {files} file(s), {syms} symbol(s).")

        # Show stats
        stats = store.stats()
        print(f"\nSymbol Index:")
        print(f"  Code:")
        print(f"    Classes:   {stats['classes']}")
        print(f"    Functions: {stats['functions']}")
        print(f"    Methods:   {stats['methods']}")

        # Show documentation stats if any
        doc_total = stats.get('documents', 0) + stats.get('sections', 0) + stats.get('subsections', 0)
        if doc_total > 0:
            print(f"  Documentation:")
            print(f"    Documents:   {stats.get('documents', 0)}")
            print(f"    Sections:    {stats.get('sections', 0)}")
            print(f"    Subsections: {stats.get('subsections', 0)}")

        print(f"  Files:     {stats['files']}")
        print(f"\nQuery with: babel map --query \"ClassName\" or \"SectionName\"")

        # Succession hint
        from ..output import end_command
        end_command("map", {"indexed": True})

    def clear_symbols(self, patterns: list, exclude: str = None):
        """
        Clear symbols matching path patterns.

        Code symbols are cache (not intent), so clearing is safe.

        Args:
            patterns: List of path patterns to clear (e.g., ['.venv', 'node_modules'])
            exclude: Optional pattern to exclude from clearing
        """
        symbols = self.symbols
        store = self._get_symbol_store()

        total_cache = 0
        total_graph = 0

        for pattern in patterns:
            print(f"Clearing symbols matching: {pattern}")
            if exclude:
                print(f"  (excluding: {exclude})")

            cache_cleared, graph_cleared = store.clear_symbols(pattern, exclude)
            total_cache += cache_cleared
            total_graph += graph_cleared

            print(f"  Cache: {cache_cleared} symbols cleared")
            print(f"  Graph: {graph_cleared} nodes deleted")

        print(f"\n{symbols.check_pass} Total cleared: {total_cache} from cache, {total_graph} from graph")

        # Show remaining stats
        stats = store.stats()
        print(f"\nRemaining symbols:")
        print(f"  Classes:   {stats['classes']}")
        print(f"  Functions: {stats['functions']}")
        print(f"  Methods:   {stats['methods']}")
        print(f"  Files:     {stats['files']}")

        # Succession hint
        from ..output import end_command
        end_command("map", {"cleared": True, "patterns": patterns})

    def query_symbols(self, name: str, symbol_type: str = None):
        """
        Query the symbol index.

        Args:
            name: Symbol name to search for
            symbol_type: Optional filter (class, function, method)
        """
        symbols = self.symbols
        store = self._get_symbol_store()

        results = store.query(name, symbol_type=symbol_type)

        if not results:
            print(f"\nNo symbols found matching \"{name}\".")
            print(f"\nBuild index with: babel map --index")
            return

        print(f"\nFound {len(results)} symbol(s) matching \"{name}\":\n")

        for sym in results:
            type_icon = {
                'class': 'C',
                'function': 'F',
                'method': 'M',
                'module': 'mod'
            }.get(sym.symbol_type, '?')

            # Format: [C] ClassName @ file.py:45-120
            location = f"{sym.file_path}:{sym.line_start}"
            if sym.line_end != sym.line_start:
                location += f"-{sym.line_end}"

            safe_print(f"  [{type_icon}] {sym.name} @ {location}")
            if sym.signature:
                safe_print(f"      {sym.signature}")
            if sym.docstring:
                safe_print(f"      \"{sym.docstring[:60]}...\"" if len(sym.docstring) > 60 else f"      \"{sym.docstring}\"")
            print()

        print(f"Load specific symbol: babel gather --file {results[0].file_path} --limit {results[0].line_end - results[0].line_start + 10}")

        # Succession hint
        from ..output import end_command
        end_command("map", {"query": name})

    def index_stats(self):
        """Show symbol index statistics."""
        symbols = self.symbols
        store = self._get_symbol_store()
        stats = store.stats()

        print("\nSymbol Index Statistics")
        print("=" * 40)

        if stats['total'] == 0:
            print(f"Status:  {symbols.check_warn} Empty (no symbols indexed)")
            print(f"\nBuild index with: babel map --index")
            return

        print(f"Status:  {symbols.check_pass} {stats['total']} symbols indexed")
        print(f"\nBreakdown:")
        print(f"  Classes:   {stats['classes']}")
        print(f"  Functions: {stats['functions']}")
        print(f"  Methods:   {stats['methods']}")
        print(f"  Files:     {stats['files']}")

        # Succession hint
        from ..output import end_command
        end_command("map", {"stats": True})


# =============================================================================
# Command Registration (Self-Registration Pattern)
# =============================================================================

COMMAND_NAME = 'map'


def register_parser(subparsers):
    """Register map command parser."""
    p = subparsers.add_parser('map',
                              help='Generate project structure map for LLM understanding')
    p.add_argument('--refresh', action='store_true',
                   help='Regenerate map from scratch (all phases)')
    p.add_argument('--update', action='store_true',
                   help='Incremental update (only changed files)')
    p.add_argument('--status', action='store_true',
                   help='Show map status')
    # Symbol index commands
    p.add_argument('--index', nargs='*', metavar='PATH',
                   help='Build code symbol index for specified path(s). Required: babel map --index <path> [<path>...]')
    p.add_argument('--index-incremental', action='store_true',
                   help='Incrementally update symbol index (git diff based, safe)')
    p.add_argument('--index-clear', nargs='+', metavar='PATTERN',
                   help='Clear symbols matching path pattern(s). Example: babel map --index-clear .venv node_modules')
    p.add_argument('--except', dest='exclude_pattern', type=str, metavar='PATTERN',
                   help='Exclude pattern from --index-clear. Example: babel map --index-clear . --except babel-tool')
    p.add_argument('--query', type=str, metavar='NAME',
                   help='Query symbol index by name')
    p.add_argument('--index-stats', action='store_true',
                   help='Show symbol index statistics')
    return p


def handle(cli, args):
    """Handle map command dispatch."""
    # Symbol index commands (check first)
    if args.index is not None:  # --index was used (may be empty list)
        if not args.index:
            # --index without paths: require explicit path (whitelist principle)
            print("Error: --index requires path(s) to index.")
            print("")
            print("Usage: babel map --index <path> [<path>...]")
            print("")
            print("Examples:")
            print("  babel map --index src/")
            print("  babel map --index babel-tool/ tests/")
            print("  babel map --index mypackage/core.py")
            print("")
            print("Why: Indexing requires explicit paths to avoid accidentally")
            print("     indexing third-party code (.venv, node_modules, etc.)")
            return
        # Index each specified path
        for path in args.index:
            cli._map_cmd.index(incremental=False, path=path)
        return
    if args.index_incremental:
        cli._map_cmd.index(incremental=True, path=None)
    elif args.index_clear:
        cli._map_cmd.clear_symbols(args.index_clear, args.exclude_pattern)
    elif args.query:
        cli._map_cmd.query_symbols(args.query)
    elif args.index_stats:
        cli._map_cmd.index_stats()
    # Original map commands
    elif args.status:
        cli._map_cmd.status()
    elif args.refresh:
        cli._map_cmd.refresh()
    elif args.update:
        cli._map_cmd.update()
    else:
        cli._map_cmd.status()