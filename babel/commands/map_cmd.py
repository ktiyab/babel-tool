"""
MapCommand — Git-native project structure mapping for LLM understanding

Generates .babel/map.md with:
- Curated directory structure (from git ls-tree)
- Key files detected by commit frequency (data-driven)
- Module docstrings and signatures
- Entry points and architecture overview

WHY: LLMs waste tokens rediscovering project structure every session.
A curated map provides instant understanding.

Architecture:
- Git handles file filtering (.gitignore respected automatically)
- Commit frequency detects important files (no hardcoded patterns)
- AST extracts Python docstrings and signatures
- Output is curated, not a dump
"""

import ast
import json
import subprocess
from collections import Counter
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Optional, Tuple

from ..commands.base import BaseCommand
from ..presentation.symbols import safe_print


class MapCommand(BaseCommand):
    """
    Git-native project structure mapping.

    P7 (Reasoning Travels): The map helps LLMs understand project structure
    without expensive exploration, preserving tokens for actual work.
    """

    MAP_HEADER = '''<!--
PROJECT MAP — Auto-generated by Babel (Git-native)
Purpose: Help LLMs understand project structure quickly

IMPORTANT: Update this file when structure changes
Regenerate: babel map --refresh
Last updated: {timestamp}
-->

'''

    def _get_map_path(self) -> Path:
        """Get path to map.md file."""
        return self.babel_dir / "map.md"

    def _get_cache_path(self) -> Path:
        """Get path to map cache file."""
        return self.babel_dir / "map_cache.json"

    # -------------------------------------------------------------------------
    # Git-Native File Operations
    # -------------------------------------------------------------------------

    def _git_command(self, args: List[str], timeout: int = 30) -> Optional[str]:
        """Run a git command and return stdout, or None on failure."""
        try:
            result = subprocess.run(
                ['git'] + args,
                cwd=self.project_dir,
                capture_output=True,
                text=True,
                timeout=timeout
            )
            if result.returncode == 0:
                return result.stdout.strip()
        except Exception:
            pass
        return None

    def _get_tracked_files(self) -> List[Path]:
        """
        Get all tracked files using git ls-files.

        .gitignore is automatically respected.
        """
        output = self._git_command(['ls-files'])
        if not output:
            return []

        return [Path(f) for f in output.split('\n') if f]

    def _get_directory_structure(self) -> Dict[str, List[str]]:
        """
        Get clean directory structure from git.

        Returns dict of {directory: [files]} for top-level dirs only.
        """
        files = self._get_tracked_files()

        structure = {}
        for f in files:
            parts = f.parts
            if len(parts) == 1:
                # Root level file
                if '.' not in structure:
                    structure['.'] = []
                structure['.'].append(str(f))
            else:
                # File in directory
                top_dir = parts[0]
                if top_dir not in structure:
                    structure[top_dir] = []
                structure[top_dir].append(str(f))

        return structure

    def _get_hot_files(self, limit: int = 15, since: str = "6 months ago") -> List[Tuple[Path, int]]:
        """
        Detect important files by git commit frequency.

        Files with more commits = more important (data-driven detection).
        """
        # Get commit history for Python files
        output = self._git_command([
            'log', '--name-only', '--format=',
            f'--since={since}', '--', '*.py'
        ])

        if not output:
            # Fallback: try without date filter
            output = self._git_command([
                'log', '--name-only', '--format=',
                '-n', '500', '--', '*.py'
            ])

        if not output:
            return []

        # Count file occurrences
        files = [f for f in output.split('\n') if f and f.endswith('.py')]
        counts = Counter(files)

        # Return top files with counts
        return [(Path(f), count) for f, count in counts.most_common(limit)]

    def _get_recent_changes(self, limit: int = 10) -> List[Tuple[Path, str]]:
        """
        Get recently changed files with their last commit message.

        Shows active development areas.
        """
        output = self._git_command([
            'log', '--name-only', '--format=%s',
            '-n', str(limit * 2), '--', '*.py'
        ])

        if not output:
            return []

        results = []
        lines = output.split('\n')
        current_message = ""

        for line in lines:
            if not line:
                continue
            if not line.endswith('.py'):
                current_message = line[:50]
            else:
                if len(results) < limit:
                    results.append((Path(line), current_message))

        return results

    def _detect_project_type(self) -> str:
        """
        Detect project type from files.

        Returns: 'python_package', 'python_cli', 'python_web', 'python_generic'
        """
        files = self._get_tracked_files()
        file_names = {f.name.lower() for f in files}

        has_pyproject = 'pyproject.toml' in file_names
        has_setup = 'setup.py' in file_names
        has_cli = 'cli.py' in file_names or '__main__.py' in file_names
        has_app = 'app.py' in file_names or 'wsgi.py' in file_names
        has_manage = 'manage.py' in file_names

        if has_manage:
            return "python_django"
        elif has_app:
            return "python_web"
        elif has_cli:
            return "python_cli"
        elif has_pyproject or has_setup:
            return "python_package"
        else:
            return "python_generic"

    def _get_entry_points(self) -> List[Path]:
        """
        Detect entry points based on project type and file patterns.
        """
        files = self._get_tracked_files()
        entry_patterns = {'main.py', 'cli.py', 'app.py', '__main__.py', 'manage.py', 'server.py', 'wsgi.py'}

        entries = []
        for f in files:
            if f.name.lower() in entry_patterns:
                entries.append(f)

        # Also check pyproject.toml for declared entry points
        return entries

    # -------------------------------------------------------------------------
    # Python AST Analysis (kept from original)
    # -------------------------------------------------------------------------

    def _extract_python_docstring(self, file_path: Path) -> Optional[str]:
        """Extract module docstring from a Python file."""
        try:
            full_path = self.project_dir / file_path
            content = full_path.read_text(encoding='utf-8', errors='ignore')

            # Limit file size to avoid memory issues
            if len(content) > 100000:  # 100KB limit
                return None

            tree = ast.parse(content)
            docstring = ast.get_docstring(tree)

            if docstring:
                lines = docstring.split('\n')
                if len(lines) > 3:
                    return '\n'.join(lines[:3]) + '...'
                return docstring
        except Exception:
            pass
        return None

    def _extract_python_signatures(self, file_path: Path, max_items: int = 5) -> List[str]:
        """Extract class and function signatures from a Python file."""
        signatures = []
        try:
            full_path = self.project_dir / file_path
            content = full_path.read_text(encoding='utf-8', errors='ignore')

            if len(content) > 100000:
                return []

            tree = ast.parse(content)

            # Only get top-level definitions
            for node in ast.iter_child_nodes(tree):
                if len(signatures) >= max_items:
                    break

                if isinstance(node, ast.ClassDef):
                    signatures.append(f"class {node.name}")
                elif isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                    if not node.name.startswith('_'):
                        prefix = "async " if isinstance(node, ast.AsyncFunctionDef) else ""
                        signatures.append(f"{prefix}def {node.name}()")
        except Exception:
            pass

        return signatures

    def _get_readme_summary(self) -> Optional[str]:
        """Extract summary from README file."""
        for name in ['README.md', 'README.rst', 'README.txt', 'README']:
            readme_path = self.project_dir / name
            if readme_path.exists():
                try:
                    content = readme_path.read_text(encoding='utf-8', errors='ignore')
                    lines = content.split('\n')

                    # Skip title, get first content paragraph
                    in_content = False
                    summary_lines = []

                    for line in lines:
                        if not in_content:
                            if line.startswith('#') or line.startswith('='):
                                in_content = True
                            continue
                        if not line.strip():
                            if summary_lines:
                                break
                            continue
                        summary_lines.append(line)
                        if len(summary_lines) >= 3:
                            break

                    if summary_lines:
                        return ' '.join(summary_lines)
                except Exception:
                    pass
        return None

    # -------------------------------------------------------------------------
    # Map Generation (Curated Output)
    # -------------------------------------------------------------------------

    def _generate_map_content(self) -> str:
        """Generate curated map.md content."""
        lines = []

        # Header
        lines.append(self.MAP_HEADER.format(
            timestamp=datetime.now().strftime('%Y-%m-%d %H:%M')
        ))

        # Title and project type
        project_type = self._detect_project_type()
        lines.append("# Project Map\n")
        lines.append(f"**Type:** {project_type.replace('_', ' ').title()}\n")

        # Overview from README or Babel purpose
        readme_summary = self._get_readme_summary()
        purpose_node = self._cli._get_active_purpose()

        if readme_summary:
            lines.append("## Overview\n")
            lines.append(f"{readme_summary}\n")
        elif purpose_node:
            purpose_text = purpose_node.content.get('purpose',
                          purpose_node.content.get('summary', ''))
            if purpose_text:
                lines.append("## Overview\n")
                lines.append(f"{purpose_text}\n")

        # Directory structure (curated)
        lines.append("## Structure\n")
        structure = self._get_directory_structure()

        for dir_name in sorted(structure.keys()):
            file_count = len(structure[dir_name])
            if dir_name == '.':
                lines.append(f"- `/` ({file_count} files) — Root")
            else:
                # Try to get purpose from __init__.py docstring
                init_path = Path(dir_name) / '__init__.py'
                purpose = ""
                if (self.project_dir / init_path).exists():
                    docstring = self._extract_python_docstring(init_path)
                    if docstring:
                        purpose = f" — {docstring.split(chr(10))[0][:50]}"
                lines.append(f"- `{dir_name}/` ({file_count} files){purpose}")
        lines.append("")

        # Entry points
        entry_points = self._get_entry_points()
        if entry_points:
            lines.append("## Entry Points\n")
            for ep in entry_points:
                docstring = self._extract_python_docstring(ep)
                desc = f" — {docstring.split(chr(10))[0][:40]}" if docstring else ""
                lines.append(f"- `{ep}`{desc}")
            lines.append("")

        # Hot files (commit frequency)
        hot_files = self._get_hot_files(limit=10)
        if hot_files:
            lines.append("## Core Files (by commit frequency)\n")
            for f, count in hot_files:
                docstring = self._extract_python_docstring(f)
                signatures = self._extract_python_signatures(f, max_items=3)

                desc = ""
                if docstring:
                    desc = docstring.split('\n')[0][:40]

                lines.append(f"### `{f}` ({count} commits)\n")
                if desc:
                    lines.append(f"> {desc}\n")
                if signatures:
                    for sig in signatures:
                        lines.append(f"- `{sig}`")
                    lines.append("")

        # Footer
        lines.append("---")
        lines.append("*Generated by `babel map` (Git-native)*")
        lines.append("*Key files detected by commit frequency, not hardcoded patterns*")

        return '\n'.join(lines)

    # -------------------------------------------------------------------------
    # Cache Management
    # -------------------------------------------------------------------------

    def _load_cache(self) -> Dict:
        """Load cache from disk."""
        cache_path = self._get_cache_path()
        if cache_path.exists():
            try:
                return json.loads(cache_path.read_text(encoding='utf-8'))
            except Exception:
                pass
        return {"files": {}, "last_update": None, "commit_hash": None}

    def _save_cache(self, cache: Dict):
        """Save cache to disk."""
        cache_path = self._get_cache_path()
        cache["last_update"] = datetime.now().isoformat()

        # Store current HEAD commit
        head = self._git_command(['rev-parse', 'HEAD'])
        if head:
            cache["commit_hash"] = head

        cache_path.write_text(json.dumps(cache, indent=2), encoding='utf-8')

    def _has_changes_since_cache(self) -> Tuple[bool, str]:
        """
        Check if there are changes since last cache using git.

        Returns: (has_changes, reason)
        """
        cache = self._load_cache()
        cached_commit = cache.get("commit_hash")

        if not cached_commit:
            return True, "No cache found"

        current_commit = self._git_command(['rev-parse', 'HEAD'])
        if not current_commit:
            return True, "Cannot get current commit"

        if cached_commit != current_commit:
            # Count commits since cache
            count = self._git_command(['rev-list', '--count', f'{cached_commit}..HEAD'])
            return True, f"{count or 'Some'} commit(s) since last update"

        # Check for uncommitted changes
        status = self._git_command(['status', '--porcelain'])
        if status:
            changed_count = len([l for l in status.split('\n') if l])
            return True, f"{changed_count} uncommitted change(s)"

        return False, "Up to date"

    # -------------------------------------------------------------------------
    # Main Commands
    # -------------------------------------------------------------------------

    def show(self):
        """Show current map content (stdout)."""
        map_path = self._get_map_path()

        if not map_path.exists():
            print("No map found. Generating...")
            self.refresh()
            return

        content = map_path.read_text(encoding='utf-8')
        safe_print(content)

        # Succession hint (centralized)
        from ..output import end_command
        end_command("map", {})

    def refresh(self):
        """Regenerate map from scratch."""
        symbols = self.symbols
        map_path = self._get_map_path()

        print("Generating project map (Git-native)...")
        print("  Scanning tracked files...")
        print("  Analyzing commit frequency...")
        print("  Extracting docstrings...")

        content = self._generate_map_content()

        # Ensure babel dir exists
        self.babel_dir.mkdir(parents=True, exist_ok=True)

        # Write map
        map_path.write_text(content, encoding='utf-8')

        # Update cache
        self._save_cache(self._load_cache())

        # Stats
        lines = content.count('\n')
        files = self._get_tracked_files()
        hot_files = self._get_hot_files()

        print(f"\n{symbols.check_pass} Map generated: {map_path}")
        print(f"  Lines: {lines}")
        print(f"  Tracked files: {len(files)}")
        print(f"  Core files detected: {len(hot_files)}")
        print(f"\nView with: babel map")

        # Succession hint (centralized)
        from ..output import end_command
        end_command("map", {})

    def update(self):
        """Incremental update (regenerates only if git has changes)."""
        symbols = self.symbols
        map_path = self._get_map_path()

        if not map_path.exists():
            print("No existing map. Running full refresh...")
            self.refresh()
            return

        has_changes, reason = self._has_changes_since_cache()

        if not has_changes:
            print(f"{symbols.check_pass} Map is up to date.")
            cache = self._load_cache()
            print(f"  Last update: {cache.get('last_update', 'unknown')}")
            return

        print(f"Changes detected: {reason}")
        print("Regenerating map...")

        content = self._generate_map_content()
        map_path.write_text(content, encoding='utf-8')
        self._save_cache(self._load_cache())

        lines = content.count('\n')
        print(f"\n{symbols.check_pass} Map updated: {map_path}")
        print(f"  Lines: {lines}")

        # Succession hint (centralized)
        from ..output import end_command
        end_command("map", {})

    def status(self):
        """Show map status."""
        symbols = self.symbols
        map_path = self._get_map_path()

        print("\nProject Map Status")
        print("=" * 40)

        # Git status
        head = self._git_command(['rev-parse', '--short', 'HEAD'])
        branch = self._git_command(['branch', '--show-current'])
        print(f"Git:     {branch or 'detached'} @ {head or 'unknown'}")

        # Map status
        if map_path.exists():
            content = map_path.read_text(encoding='utf-8')
            lines = content.count('\n')
            mtime = datetime.fromtimestamp(map_path.stat().st_mtime)

            print(f"Status:  {symbols.check_pass} Exists")
            print(f"Path:    {map_path}")
            print(f"Size:    {lines} lines")
            print(f"Updated: {mtime.strftime('%Y-%m-%d %H:%M')}")

            # Check if up to date
            has_changes, reason = self._has_changes_since_cache()
            if has_changes:
                print(f"Version: {symbols.check_warn} {reason}")
            else:
                print(f"Version: {symbols.check_pass} Up to date")
        else:
            print(f"Status:  {symbols.check_fail} Not found")
            print(f"\nGenerate with: babel map --refresh")

        # File stats
        files = self._get_tracked_files()
        py_files = [f for f in files if f.suffix == '.py']
        print(f"\nProject: {len(files)} tracked files ({len(py_files)} Python)")

        # Succession hint (centralized)
        from ..output import end_command
        end_command("map", {})

    def init_if_missing(self) -> bool:
        """Create map if it doesn't exist."""
        map_path = self._get_map_path()

        if not map_path.exists():
            self.refresh()
            return True

        return False